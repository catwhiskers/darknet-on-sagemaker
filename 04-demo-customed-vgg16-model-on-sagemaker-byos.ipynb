{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bring Your Own Script on SageMaker \n",
    "* Prepare the script \n",
    "* Get the trained model \n",
    "* Inference on Tensorflow 2.2.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import boto3 \n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "vgg16_estimator = TensorFlow(entry_point='tf22-byos/merge.py',\n",
    "                             role=role,\n",
    "                             train_instance_count=1,\n",
    "                             train_instance_type='ml.p3.2xlarge',\n",
    "                             framework_version='2.1.0',\n",
    "                             py_version='py3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training locally \n",
    "* test container locally by dogs_and_cat.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.session.Session().region_name\n",
    "bucket = 'ws-yolov4-yianc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "job_name = 'vgg16-' + now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train='s3://{}/dogs_and_cat/input/data/train/'.format(bucket)\n",
    "validation='s3://{}/dogs_and_cat/input/data/validation/'.format(bucket)\n",
    "outpath='s3://{}/model/'.format(bucket)\n",
    "(train, validation, outpath) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg16_estimator.fit({'train': train,\n",
    "               'validation': validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.describe_training_job(TrainingJobName=vgg16_estimator.latest_training_job.name)\n",
    "model_path = response['ModelArtifacts']['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sagemaker-us-east-1-230755935769/tensorflow-training-2020-11-05-12-02-53-032/output/model.tar.gz . \n",
    "!tar -xvf model.tar.gz\n",
    "!tar -xvf tlmodel.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "new_model = tf.keras.models.load_model('tlmodel')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pathlib\n",
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "\n",
    "train_dir = pathlib.Path(train_dir)\n",
    "validation_dir = pathlib.Path(validation_dir)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "    one_hot = class_names == parts[-2]\n",
    "    one_hot = tf.dtypes.cast(one_hot, tf.int32)\n",
    "  # Integer encode the label\n",
    "    return tf.cast(tf.argmax(one_hot), tf.int64) \n",
    "\n",
    "\n",
    "img_height = IMG_SIZE[0]\n",
    "img_width = IMG_SIZE[0]\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    return img\n",
    "\n",
    "def process_path(file_path):\n",
    "    print(file_path)\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def get_dataset(data_dir): \n",
    "    image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "    print(image_count)\n",
    "    list_ds = tf.data.Dataset.list_files(str(train_dir/'*/*'), shuffle=False)\n",
    "    list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n",
    "    return list_ds\n",
    "\n",
    "train_dataset = get_dataset(train_dir)\n",
    "val_dataset = get_dataset(validation_dir)\n",
    "\n",
    "class_names = np.array(sorted([item.name for item in train_dir.glob('*') if item.name != \"LICENSE.txt\"]))\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "val_dataset = val_dataset.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "  return ds\n",
    "\n",
    "train_dataset = configure_for_performance(train_dataset)\n",
    "\n",
    "val_dataset = configure_for_performance(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_batch, label_batch = val_dataset.as_numpy_iterator().next()\n",
    "predictions = new_model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
